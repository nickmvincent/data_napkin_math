inputs:
- variable: dataset_size__llama3__tokens
  variable_type: dataset_size
  entity: llama3
  units: tokens
  nice_name: Total pre-training tokens (Llama 3)
  value: 15000000000000.0
  scale: 1e9
  display_units: billions of tokens
  value_description: Total tokens used to pre-training a model
  key_assumption: > 
    We can use 15 trillion as a default value based on the assumption that most frontier models use roughly same pre-training size.
    15T is the number cited in Llama3 model card and close to the FineWeb size.
  source_url: https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md
  source_notes: Source is the Llama 3 model card. It describes total number of tokens for pre-training.
  
- variable: yearly_revenue__openai__dollars
  variable_type: yearly_revenue
  entity: openai
  units: dollars
  nice_name: Revenue from AI (OpenAI)
  value: 3490000000.0
  scale: 1e6
  display_units: millions of dollars
  value_description: Value generated by AI in dollars
  key_assumption: Assuming all 2024 OpenAI revenue is from LLMs
  source_url: https://www.bloomberg.com/news/articles/2024-06-12/openai-doubles-annualized-revenue-to-3-4-billion-information
  source_notes: business news coverage of openai
  related_inputs:
    - yearly_revenue__anthropic__dollars

- variable: yearly_revenue__anthropic__dollars
  variable_type: yearly_revenue
  entity: anthropic
  units: dollars
  nice_name: Revenue from AI (Anthropic)
  value: 1000000000.0
  scale: 1e6
  display_units: millions of dollars
  value_description: Value generated by AI in dollars
  key_assumption: assuming all 2024 Anthropic revenue is from LLMs
  source_url: https://www.pymnts.com/artificial-intelligence-2/2024/anthropic-revenue-reportedly-set-to-jump-to-1-billion-this-year/
  source_notes: business news coverage of anthropic
  related_inputs:
    - yearly_revenue__openai__dollars

- variable: dataset_attribute__redpajama__tokens_per_contribution
  variable_type: dataset_attribute
  entity: redpajama
  units: dataset_attribute__redpajama__tokens_per_contribution
  nice_name: Average number of a token in a single document (Red Pajama dataset)
  value: 1413.0
  scale: 1
  display_units: tokens per contribution
  value_description: Average number of tokens in a single 'contribution'
  key_assumption: Working with averages here
  source_url: https://github.com/togethercomputer/RedPajama-Data
  source_notes: RedPajama readme reports a ratio of documents to tokens (after dedupe). We use the English figures (20.5T tokens / 14.5B documents)

- variable: total_books__books3__books
  variable_type: dataset
  entity: books3
  units: books
  nice_name: Total number of books in Books3
  value: 196640.0
  scale: 1
  display_units: books
  value_description: Number of books in Books3
  key_assumption: N/A
  source_url: https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/books3-ai-training-dataset
  source_notes: Entry in the AIAAIC repository.

- variable: average_length__book__words
  variable_type: dataset
  entity: book
  units: words
  nice_name: Average number of words per book
  value: 80000.0
  scale: 1
  display_units: words
  value_description: An average number of words per book
  key_assumption: Average number of words per book
  source_url: https://www.penguin.co.uk/articles/2020/09/book-length-debate-fiction-long-novels
  source_notes: No additional notes.

- variable: training_detail__openai__words_per_token
  variable_type: training_detail
  entity: openai
  units: words_per_token
  nice_name: Average words per token
  value: 0.75
  scale: 1
  display_units: words per token
  value_description: Average number of words per token
  key_assumption: Average across random queries
  source_url: https://platform.openai.com/tokenizer
  source_notes: OpenAI Tokenizer

- variable: wage_data__generic_freelance_lower__dollars_per_word
  variable_type: wage_data
  entity: generic_freelance_lower
  units: dollars_per_word
  nice_name: Freelance rate per word (low estimate)
  value: 0.10
  scale: 1
  display_units: dollars per word
  value_description: Freelance rate per word (beginner)
  key_assumption: Rate estimate based on market conditions
  source_url: https://www.clearvoice.com/resources/how-much-to-pay-a-freelance-writer/
  source_notes: Survey by ClearVoice, a company

- variable: wage_data__generic_freelance_higher__dollars_per_word
  variable_type: wage_data
  entity: generic_freelance_higher
  units: dollars_per_word
  nice_name: Freelance rate per word (high estimate)
  value: 1.00
  scale: 1
  display_units: dollars per word
  value_description: Freelance rate per word (expert)
  key_assumption: Rate estimate based on market conditions
  source_url: https://www.clearvoice.com/resources/how-much-to-pay-a-freelance-writer/
  source_notes: Survey by ClearVoice, a company

- variable: group_size_users__reddit__daily_active_users
  variable_type: group_size
  entity: reddit
  units: daily_active_users
  nice_name: Number of Reddit daily active users
  value: 267500000.0
  scale: 1e6
  display_units: millions of daily active users
  value_description: Number of Reddit daily active users
  key_assumption: None
  source_url: https://backlinko.com/reddit-users
  source_notes: article about # of reddit users

- variable: deal_value__reddit_google__dollars
  variable_type: deal_value
  entity: reddit_google
  units: dollars
  nice_name: Payment made to Reddit by Google
  value: 60000000.0
  scale: 1e6
  display_units: millions of dollars
  value_description: Payment made to Reddit by Google
  key_assumption: None
  source_url: https://www.cbsnews.com/news/google-reddit-60-million-deal-ai-training/
  source_notes: CBS news coverage

- variable: deal_value__taylorandfrancis_microsoft__dollars
  variable_type: deal_value
  entity: taylorandfrancis_microsoft
  units: dollars
  nice_name: Value of the Taylor and Francis deal
  value: 10000000.0
  scale: 1e6
  display_units: millions of dollars
  value_description: Value of the Taylor and Francis deal
  key_assumption: None
  source_url: https://www.thebookseller.com/news/academic-authors-shocked-after-taylor--francis-sells-access-to-their-research-to-microsoft-ai
  source_notes: news coverage of deal

- variable: deal_value__newscorp__dollars
  variable_type: deal_data
  entity: newscorp
  units: dollars
  nice_name: Value of the News Corp deal
  value: 50000000.0
  scale: 1e6
  display_units: millions of dollars
  value_description: Value of the News Corp deal
  key_assumption: Not specified
  source_url: https://www.nytimes.com/2024/05/22/business/media/openai-news-corp-content-deal.html
  source_notes: notes here

- variable: group_size__taylorandfrancis__articles
  variable_type: group_size
  entity: taylorandfrancis
  units: articles
  nice_name: Number of Taylor and Francis Articles
  value: 5291000
  scale: 1e6
  display_units: millions of articles
  value_description: Number of Taylor and Francis Articles
  key_assumption: assuming each article has 1 unique author
  source_url: https://www.tandfonline.com/#:~:text=Advanced%20search.%205%2C291%2C000+%20articles.%20Find%20a%20journal.
  source_notes: T&F search engine

- variable: group_size__wsj__journalists
  variable_type: group_size
  entity: wsj
  units: journalists
  nice_name: Number of WSJ journalists
  value: 2000.0
  scale: 1
  display_units: people
  value_description: Number of WSJ journalists
  key_assumption: Not specified
  source_url: https://en.wikipedia.org/wiki/The_Wall_Street_Journal
  source_notes: Wikipedia article

- variable: group_size__newscorp__employees
  variable_type: group_size
  entity: newscorp
  units: employees
  nice_name: Number of News Corp employees
  value: 25000.0
  scale: 1
  display_units: people
  value_description: Number of News Corp employees
  key_assumption: Not specified
  source_url: https://en.wikipedia.org/wiki/News_Corp
  source_notes: Wikipedia article (primary source is sec.gov)

- variable: group_size__world__people
  variable_type: group_size
  entity: world
  units: people
  nice_name: Number of people on Earth
  value: 8100000000.0
  scale: 1e9
  display_units: billions of people
  value_description: Number of people on Earth
  key_assumption: Not specified
  source_url: https://www.worldometers.info/world-population/
  source_notes: Worldometer website

# - variable: contribution_distribution__wikipedia__unknown
#   variable_type: distribution
#   entity: wikipedia
#   units: contributions
#   nice_name: Distribution of Wikipedia contributions
#   value: .nan
#   scale: 1
#   display_units: unknown
#   value_description: Power-law distribution for Wikipedia contributions
#   key_assumption: Not specified
#   source_url: https://p2pmodels.eu/power-law-distribution-characterize-wiki-communities/
#   source_notes: No additional notes.


calculations:
  - title: "Distributing the 'value generated' by AI to everyone in the world"
    description: "If we were to immediately distribute AI revenue to everyone on Earth, how much would each person receive?"
    inputs:
      - yearly_revenue__openai__dollars
      - total_population__world__people
    result:
      label: "Dividend per person"
      units: dollars
      value: 0
    explanation: "yearly_revenue__openai__dollars / total_population__world__people"

  - title: "Commissiong a fresh LLM dataset"
    description: How much would it cost to pay for a brand new LLM-scale pre-training dataset assuming moderate freelance writing wages. 
    inputs:
      - words_per_token__generic__words_per_token
      - freelance_rate_per_word_high
      - dataset_size__llama3__tokens
    result:
      label: Total cost
      units: dollars
      value: 0
    explanation: "dataset_size__llama3__tokens * words_per_token__generic__words_per_token * freelance_rate_per_word_high"
  
  - title: "Distributing model 'value generated' per token"
    description: >
      Estimate a $/token value. Take some estimate of value generated (e.g., the revenue of an AI company) and divide by the
      number of tokens used to train that company's models.
    inputs:
      - yearly_revenue__openai__dollars
      - dataset_size__llama3__tokens
    result:
      label: "Revenue per Token"
      value: 0
    explanation: "yearly_revenue__openai__dollars / dataset_size__llama3__tokens"
  
  - title: "Average Contribution Size"
    description: "Estimate of the average contribution size in tokens based on the dataset size and number of contributions."
    inputs:
      - dataset_size__llama3__tokens
      - average_tokens_per_contribution__redpajama__tokens_per_contribution
    result:
      label: "Average Contribution Size"
      value: 0
    explanation: "dataset_size__llama3__tokens / average_tokens_per_contribution__redpajama__tokens_per_contribution"
  - title: "Revenue per contribution"
    description: "Calculate the revenue generated per contribution based on the average tokens per contribution and revenue per token."
    inputs:
      - average_tokens_per_contribution__redpajama__tokens_per_contribution
      - yearly_revenue__openai__dollars
      - dataset_size__llama3__tokens
    result:
      label: "Revenue per Contribution"
      value: 0
    explanation: "(yearly_revenue__openai__dollars / dataset_size__llama3__tokens) * average_tokens_per_contribution__redpajama__tokens_per_contribution"
  - title: "Revenue per Book in Books3"
    description: "Estimate the revenue generated per book in the Books3 dataset."
    inputs:
      - total_books__books3__books
      - average_length__book__words
      - yearly_revenue__openai__dollars
      - dataset_size__llama3__tokens
    result:
      label: "Revenue per Book"
      value: 0
    explanation: "(yearly_revenue__openai__dollars / dataset_size__llama3__tokens) * (total_books__books3__books * average_length__book__words)"
  - title: "Dataset Coverage Ratio"
    description: "Calculate the ratio of books in the Books3 dataset relative to the total number of tokens."
    inputs:
      - total_books__books3__books
      - average_length__book__words
      - dataset_size__llama3__tokens
    result:
      label: "Dataset Coverage Ratio"
      value: 0
    explanation: "(total_books__books3__books * average_length__book__words) / dataset_size__llama3__tokens"

  - title: "Value per Reddit User"
    description: "Estimate the value of the Reddit-Google deal per Reddit daily active user."
    inputs:
      - deal_value__reddit_google__millions_dollar
      - daily_active_users__reddit__users
    result:
      label: "Value per Reddit User"
      units: dollars
      value: 0
    explanation: "(deal_value__reddit_google__millions_dollar * 1e6) / (daily_active_users__reddit__users * 1e3)"

  - title: "Freelance Cost per Book in Books3"
    description: "Calculate the cost of paying freelance writers to create content equivalent to a book in the Books3 dataset, using high freelance rates."
    inputs:
      - average_length__book__words
      - freelance_rate_high__generic__dollars_per_word
    result:
      label: "Freelance Cost per Book"
      units: dollars
      value: 0
    explanation: "average_length__book__words * freelance_rate_high__generic__dollars_per_word"

  - title: "Total Freelance Cost for Books3"
    description: "Estimate the total cost to pay freelance writers to create content equivalent to all books in the Books3 dataset."
    inputs:
      - total_books__books3__books
      - average_length__book__words
      - freelance_rate_high__generic__dollars_per_word
    result:
      label: "Total Freelance Cost for Books3"
      units: dollars
      value: 0
    explanation: "total_books__books3__books * average_length__book__words * freelance_rate_high__generic__dollars_per_word"

  - title: "Revenue per WSJ Journalist"
    description: "Estimate the revenue per journalist at WSJ based on News Corp's total revenue from their AI deal."
    inputs:
      - deal_value__newscorp__dollars
      - journalists__wsj__count
    result:
      label: "Revenue per WSJ Journalist"
      units: dollars
      value: 0
    explanation: "deal_value__newscorp__dollars / journalists__wsj__count"
