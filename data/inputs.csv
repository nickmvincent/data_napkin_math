variable,value,units,value_description,variable_type,confidence_in_number,key_assumption,source_url,source_notes
dataset_size__llama3__tokens,15000000000000.0,tokens,Total tokens used to pre-training a model,dataset_size,,"We can use 15 trillion as a default value based on the assumption that most frontier models use roughly same pre-training size. 15T is the number cited in Llama3 model card and close to the FineWeb size.
",https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md,Source is the Llama 3 model card. It describes total number of tokens for pre-training.
yearly_revenue__openai__dollars,3490000000.0,dollars,Value generated by AI in dollars,yearly_revenue,,Assuming all 2024 OpenAI revenue is from LLMs,https://www.bloomberg.com/news/articles/2024-06-12/openai-doubles-annualized-revenue-to-3-4-billion-information,business news coverage of openai
yearly_revenue__anthropic__dollars,1000000000.0,dollars,Value generated by AI in dollars,yearly_revenue,,assuming all 2024 Anthropic revenue is from LLMs,https://www.pymnts.com/artificial-intelligence-2/2024/anthropic-revenue-reportedly-set-to-jump-to-1-billion-this-year/,business news coverage of anthropic
dataset_attribute__redpajama__tokens_per_contribution,1413.0,tokens_per_contribution,Average number of tokens in a single 'contribution',dataset_attribute,,Working with averages here,https://github.com/togethercomputer/RedPajama-Data,RedPajama readme reports a ratio of documents to tokens (after dedupe). We use the English figures (20.5T tokens / 14.5B documents)
total_books__books3__books,196640.0,books,Number of books in Books3,dataset,,N/A,https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/books3-ai-training-dataset,Entry in the AIAAIC repository.
average_length__book__words,80000.0,words,An average number of words per book,dataset,,Average number of words per book,https://www.penguin.co.uk/articles/2020/09/book-length-debate-fiction-long-novels,No additional notes.
training_detail__openai__words_per_token,0.75,words_per_token,Average number of words per token,training_detail,,Average across random queries,https://platform.openai.com/tokenizer,OpenAI Tokenizer
wage_data__generic_freelance_lower__dollars_per_word,0.1,dollars_per_word,Freelance rate per word (beginner),wage_data,,Rate estimate based on market conditions,https://www.clearvoice.com/resources/how-much-to-pay-a-freelance-writer/,"Survey by ClearVoice, a company"
wage_data__generic_freelance_higher__dollars_per_word,1.0,dollars_per_word,Freelance rate per word (expert),wage_data,,Rate estimate based on market conditions,https://www.clearvoice.com/resources/how-much-to-pay-a-freelance-writer/,"Survey by ClearVoice, a company"
group_size_users__reddit__daily_active_users,267500000.0,daily_active_users,Number of Reddit daily active users,group_size,,None,https://backlinko.com/reddit-users,article about
deal_value__reddit_google__dollars,60000000.0,dollars,Payment made to Reddit by Google,deal_value,,None,https://www.cbsnews.com/news/google-reddit-60-million-deal-ai-training/,CBS news coverage
deal_value__taylorandfrancis_microsoft__dollars,10000000.0,dollars,Value of the Taylor and Francis deal,deal_value,,None,https://www.thebookseller.com/news/academic-authors-shocked-after-taylor--francis-sells-access-to-their-research-to-microsoft-ai,news coverage of deal
deal_value__newscorp__dollars,50000000.0,dollars,Value of the News Corp deal,deal_data,,Not specified,https://www.nytimes.com/2024/05/22/business/media/openai-news-corp-content-deal.html,notes here
group_size__taylorandfrancis__articles,5291000,articles,Number of Taylor and Francis Articles,group_size,,assuming each article has 1 unique author,https://www.tandfonline.com/#:~:text=Advanced%20search.%205%2C291%2C000+%20articles.%20Find%20a%20journal.,T&F search engine
group_size__wsj__journalists,2000.0,journalists,Number of WSJ journalists,group_size,,Not specified,https://en.wikipedia.org/wiki/The_Wall_Street_Journal,Wikipedia article
group_size__newscorp__employees,25000.0,employees,Number of News Corp employees,group_size,,Not specified,https://en.wikipedia.org/wiki/News_Corp,Wikipedia article (primary source is sec.gov)
group_size__world__people,8100000000.0,people,Number of people on Earth,group_size,,Not specified,https://www.worldometers.info/world-population/,Worldometer website
